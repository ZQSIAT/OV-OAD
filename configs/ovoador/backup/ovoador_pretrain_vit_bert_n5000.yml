_base_: '../default.yml'
model_name: 'ovoador' # display name in the logger
output: /mnt/petrelfs/heyinan/00_zqs/data/exps/n5000_b256_d768_soft_mask
device: cuda
debug: False
print_freq: 10

data:
  with_dc: False
  train: 
      root_dir: 'phdd:s3://internvid_extc_feats_4fps/CLIP_ViT_B_16_768/'
      meta_file: '/mnt/petrelfs/heyinan/00_zqs/code/ovoad/extract_features/internvid10w_20m_oad_instances.json'
      anno_file: '/mnt/petrelfs/heyinan/00_zqs/code/ovoad/extract_features/internvid10w_anno_106176.pickle'
      read_from: petrel
      use_nvideos: 5000
      nonzero: 8  # 2000/8: 1.67M; 5000/8: 3.95M; 10000/8: 7.41M; 12000/8: 8.74M; 15000/8: 10.75M; 106176/8: 63.05M
      enc_steps: 128
      dec_steps: 8
      use_dali: True
      batch_size: 256  # 256
      input_size: 224
      test_resize: 256

      image_reader:
          type: pil
      sampler:
          type: distributed_epoch
      transforms:
          type: STANDARD
      use_ranked: False
      
      use_entity: ${model.use_entityloss}
      mask_type: class
      use_distilbert: True
  
  val:
      type: clip
      read_from: petrel
      use_dali: True
      batch_size: 64
      num_workers: 4
      pin_memory: False
      input_size: 224
      test_resize: 256
      
      root_dir: '/mnt/cache/share/images/val/'
      meta_file: 'imagenet_info/val.json'
      # you can change it to imagenet_info relative path, file already in gitlab
      image_reader:
          type: pil
      sampler:
          type: distributed
      transforms:
          type: ONECROP
      evaluator:
          type: imagenet
          kwargs:
              topk: [1, 5]
      label_texts_ensemble: 'prompt1'
          
  text_aug:
    max_seq_len: 77
    multi_label: 0 # we do not use multi-label contrastive 
    word_type: 'noun'

model:
  type: MultiLabelContrastive
  img_encoder:
    type: GroupViT
    embed_dim: 768  # small : 384; base: 768
    num_heads: [8, 8]  # small : [6, 6] 
    embed_factors: [1, 1]
    depths: [6, 6]
    num_group_tokens: [64, 0]
    num_output_groups: [8]
    drop_rate: 0.0
    drop_path_rate: 0.1
    no_patch_embed: true
    enc_steps: ${data.train.enc_steps}
    dec_steps: ${data.train.dec_steps}
    patch_norm: false
    imgnet_pretrained: null
    fixed: false
    imgnet_pretrained_checkpoint: '/mnt/petrelfs/heyinan/00_zqs/code/ovoad/models/pretrained_models/dino_vitbase16_pretrain.pth'

  text_encoder:
    type: Bert
    context_length: 77
    width: 768
    layers: 6
    vocab_size: 49408
    pretrained: true
    fixed: false
  contrast_temperature: 0.07
  proj_num_layers: 2
  output_dim: 256
  multi_label: ${data.text_aug.multi_label}
  use_entityloss: false
  use_maskloss: true
  use_matcher: false
  maskloss_weight: 1.0
  
train:
  epochs: 30
  # base_lr: 1.6e-3 
  # warmup_lr: 4e-6 
  # min_lr: 4e-5 
  base_lr: 6.4e-4
  warmup_lr: 1.6e-5
  min_lr: 1.6e-4
  clip_grad: 5.0
checkpoint:
  auto_resume: true
  resume: null
  save_freq: 5
evaluate:
  eval_freq: 1
  oad:
    out_dim768: true
    cfg: oad/configs/_base_/datasets/thomus14_enc128.py
    template: simple_kinectics  # full_kinectics, subset_kinectics, simple_imagenet, etc
